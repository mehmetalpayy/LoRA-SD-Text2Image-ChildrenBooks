{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qax4VrhludOw"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -q\n",
        "!pip install diffusers[\"torch\"] transformers -q\n",
        "!pip install accelerate -q\n",
        "!pip install git+https://github.com/huggingface/diffusers -q\n",
        "!pip install -U peft -q\n",
        "!pip install git+https://github.com/huggingface/peft.git -q\n",
        "!pip install -U peft transformers -q\n",
        "\n",
        "%pip install --quiet --upgrade mediapy -q\n",
        "\n",
        "!pip install gradio -q\n",
        "!pip install safetensors -q\n",
        "!pip install omegaconf -q\n",
        "!pip install torchsde -q\n",
        "!pip install openai==0.28 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9jeq2pTujFG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTbl0dLRuk3A"
      },
      "outputs": [],
      "source": [
        "# optional: remove warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5AAK3DHumR8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import autocast\n",
        "import mediapy as media\n",
        "import gradio as gr\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from diffusers import EulerDiscreteScheduler, DPMSolverSDEScheduler\n",
        "from diffusers.schedulers.scheduling_dpmsolver_multistep import DPMSolverMultistepScheduler\n",
        "import safetensors\n",
        "import openai\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg79XI-FjiDI"
      },
      "outputs": [],
      "source": [
        "\n",
        "openai.api_key = \"\" # enter your openai api key to start\n",
        "# def openai_chat(prompt):\n",
        "#     completions = openai.Completion.create(\n",
        "#         engine=\"gpt-3.5-turbo-16k\",\n",
        "#         prompt=prompt,\n",
        "#         max_tokens=1024,\n",
        "#         n=1,\n",
        "#         temperature=0.5,\n",
        "#     )\n",
        "\n",
        "#     message = completions.choices[0].text\n",
        "#     return message.strip()\n",
        "\n",
        "def openai_chat(chat_prompt):\n",
        "    completions = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": chat_prompt}\n",
        "        ]\n",
        "    )\n",
        "    # Sonucu strip() ile temizleyin\n",
        "    return completions.choices[0].message['content'].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2b57xDfi3zf"
      },
      "outputs": [],
      "source": [
        "def promptDesign(prompt):\n",
        "\n",
        "  famous_artists = \"Vincent van Gogh, Pablo Picasso, Leonardo da Vinci\"\n",
        "  # famous_artists = \"Eric Carle, Dr. Seuss, Beatrix Potter\"\n",
        "\n",
        "  chat_prompt = f\"\"\"\n",
        "  I will give you the 'children's book text' and a formula for the image prompt. Create a formula for the children's book\n",
        "  text to determine key points of text.\n",
        "  Hereâ€™s a formula for a Stable Diffusion image prompt: An image of [adjective] [subject] [doing action],\n",
        "  [creative lighting style], detailed, realistic,\n",
        "  trending on artstation, in the style of {famous_artists}.\n",
        "  Here's a children's book text to create prompt:\n",
        "  {prompt}\n",
        "\n",
        "  Just write the image prompt in English. Only give me prompt, do not write anything different.\n",
        "  \"\"\"\n",
        "  return openai_chat(chat_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1eRQr43unpW"
      },
      "outputs": [],
      "source": [
        "def image_generator(enable_chatgpt_template, prompt, x_dimension, y_dimension, seed_enabled, seed, enable_inference_steps, num_inference_steps,\n",
        "                    guidance=7.5):\n",
        "\n",
        "    defaultSeed = -1\n",
        "    inference_steps = 0\n",
        "    # Check if all dimensions are provided\n",
        "    if prompt and x_dimension and y_dimension:\n",
        "\n",
        "        # Convert dimensions to integers\n",
        "        x_dimension = int(x_dimension)\n",
        "        y_dimension = int(y_dimension)\n",
        "\n",
        "        # Create diffusion pipeline, load safetensors model file from project folder\n",
        "        # pipe = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16)\n",
        "        pipe = StableDiffusionPipeline.from_pretrained(\"SG161222/Realistic_Vision_V2.0\", torch_dtype=torch.float16)\n",
        "        pipe = pipe.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        pipe.safety_checker = None\n",
        "\n",
        "        if enable_chatgpt_template:\n",
        "          prompt = promptDesign(prompt)\n",
        "\n",
        "        # Apply inference steps if enabled\n",
        "        if enable_inference_steps:\n",
        "            inference_steps = num_inference_steps\n",
        "\n",
        "        if seed_enabled:\n",
        "          defaultSeed = seed\n",
        "\n",
        "        pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "        # pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config, use_karras_sigmas=True)\n",
        "        # pipe.scheduler = DPMSolverSDEScheduler.from_config(pipe.scheduler.config, use_karras_sigmas=True)\n",
        "        # lora_path = \"mehmetalpy/Children_stories\"\n",
        "        # lora_path = \"artificialguybr/StoryBookRedmond-V2\"\n",
        "        lora_path = \"mehmetalpy/the-kidbook\"\n",
        "        pipe.load_lora_weights(lora_path, weight_name=\"COOLKIDS_MERGE_V2.5.safetensors\")\n",
        "\n",
        "        generator = torch.Generator(\"cuda\").manual_seed(defaultSeed)\n",
        "        # prompt = \"closeup, a family portrait, momn, dad, kitchen in the background\"\n",
        "        # h=512\n",
        "        # w=512\n",
        "        # steps=40\n",
        "        # guidance=7.5\n",
        "        lora_weight=1\n",
        "        # cfg_scale=5\n",
        "        # num_images=1\n",
        "        negativePrompt = \"ngtvH, ngtv, ngtvB\"\n",
        "\n",
        "        with autocast(\"cuda\"):\n",
        "          image = pipe(prompt, generator=generator, cross_attention_kwargs = {\"scale\": lora_weight}, height=y_dimension,\n",
        "                       width=x_dimension, num_inference_steps=inference_steps, guidance_scale=guidance,\n",
        "                       negative_prompt=negativePrompt).images # num_images_per_prompt=num_images\n",
        "\n",
        "\n",
        "        # Return generated and resized image\n",
        "        return prompt, image[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zMhZC1g4rSh"
      },
      "outputs": [],
      "source": [
        "# prompt =\"closeup, a family portrait, momn, dad, kitchen in the background\"\n",
        "# media.show_images([image_generator(prompt, x_dimension=1024, y_dimension=1024, seed_enabled=True, seed=-1, enable_inference_steps=True, num_inference_steps=40, guidance=7.5)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF3YAaB7uo6h"
      },
      "outputs": [],
      "source": [
        "# Options for the radio buttons\n",
        "dimensions = [\"512\", \"640\", \"768\", \"1024\"]\n",
        "\n",
        "# Build the Gradio interface\n",
        "Interface_ChildBook = gr.Interface(\n",
        "    fn=image_generator,\n",
        "    inputs=[\n",
        "        gr.Checkbox(label=\"Enable ChatGPT Template\"),\n",
        "        gr.Textbox(label=\"Text Prompt\", placeholder=\"Type your prompt here...\"),\n",
        "        gr.Radio(label=\"X Dimension\", choices=dimensions),\n",
        "        gr.Radio(label=\"Y Dimension\", choices=dimensions),\n",
        "        gr.Checkbox(label=\"Enable Seed\"),\n",
        "        gr.Number(label=\"Set Seed Number\"),\n",
        "        gr.Checkbox(label=\"Enable Inference Steps\"),\n",
        "        gr.Slider(label=\"Set Inference Steps (Optimal: 25-60)\"),\n",
        "        gr.Number(label=\"Guidance (Optimal: 3.5-9)\", value=7.5),\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Prompt\"),\n",
        "        gr.Image(label=\"Generated Image\"),\n",
        "    ],\n",
        "    title=\"Text-to-Image Generator for Children Books\",\n",
        "    theme=gr.themes.Soft(),\n",
        "    description=\"Book Images Generator with Stable Diffusion and LoRA Models. If you do not know How to Write LoRA prompt then click Enable ChatGPT Template\",\n",
        "    examples=[\n",
        "        [False, \"closeup, a family portrait, momn, dad, kitchen in the background\", \"1024\", \"1024\", True, 4128965862, True, 40, 7.5],\n",
        "        [False, \"a Wolf is camping, kid, Desert Scrub\", \"1024\", \"1024\", True, 3490148812, True, 40, 7.5],\n",
        "        [False, \"a Porcupine is camping, kid, Intertidal Zone\", \"1024\", \"1024\", True, 3435676572, True, 40, 7.5],\n",
        "        [False, \"a Meerkat is camping, kid, Savannah\", \"1024\", \"1024\", True, 313220802, True, 40, 7.5],\n",
        "        [False, \"a Chilean girl in a wasteland, explorer suit, alien planet, space, starfield, kid, Rocky Shore\", \"1024\", \"1024\", True, 3299919458, True, 40, 7.5],\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Start interface\n",
        "Interface_ChildBook.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN-ezIl3w-n9"
      },
      "outputs": [],
      "source": [
        "gr.close_all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkF628CyiwX-"
      },
      "outputs": [],
      "source": [
        "# # unload GPU\n",
        "# with torch.no_grad():\n",
        "#     torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}